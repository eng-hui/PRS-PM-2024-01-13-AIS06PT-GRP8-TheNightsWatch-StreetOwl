{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paths\n",
    "original_dataset_dir = 'dataset'  # Your current dataset directory\n",
    "output_dir = 'split_dataset'       # New directory for the split dataset\n",
    "categories = ['sparse', 'dense', 'crowded']  # Class categories\n",
    "\n",
    "# Split ratios\n",
    "train_ratio = 0.7  # 70% for training\n",
    "val_ratio = 0.2    # 20% for validation\n",
    "test_ratio = 0.1   # 10% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create output directories for train, val, and test\n",
    "for split in ['train', 'val', 'test']:\n",
    "    for category in categories:\n",
    "        split_dir = os.path.join(output_dir, split, category)\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "# Function to split the dataset\n",
    "def split_dataset():\n",
    "    for category in categories:\n",
    "        category_dir = os.path.join(original_dataset_dir, category)\n",
    "        images = os.listdir(category_dir)  # List all image files in the category\n",
    "        random.shuffle(images)  # Shuffle to ensure randomness\n",
    "\n",
    "        total_images = len(images)\n",
    "        train_count = floor(train_ratio * total_images)\n",
    "        val_count = floor(val_ratio * total_images)\n",
    "        test_count = total_images - train_count - val_count  # Remaining for test\n",
    "\n",
    "        # Split into train, val, test\n",
    "        train_images = images[:train_count]\n",
    "        val_images = images[train_count:train_count + val_count]\n",
    "        test_images = images[train_count + val_count:]\n",
    "\n",
    "        # Copy images to respective directories\n",
    "        for image in train_images:\n",
    "            src = os.path.join(category_dir, image)\n",
    "            dst = os.path.join(output_dir, 'train', category, image)\n",
    "            shutil.copy(src, dst)\n",
    "        \n",
    "        for image in val_images:\n",
    "            src = os.path.join(category_dir, image)\n",
    "            dst = os.path.join(output_dir, 'val', category, image)\n",
    "            shutil.copy(src, dst)\n",
    "        \n",
    "        for image in test_images:\n",
    "            src = os.path.join(category_dir, image)\n",
    "            dst = os.path.join(output_dir, 'test', category, image)\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "    print(\"Dataset has been successfully split into train, val, and test sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has been successfully split into train, val, and test sets.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run the split function\n",
    "split_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
