{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "project = os.path.join(\"..\",\"..\",\"runs\")\n",
    "yolo_models = [\"yolov8s\", \"yolov8m\"] # select yolov8s and yolov8m for further hyperparamter search and finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Ultralytics YOLOv8.2.93  Python-3.10.6 torch-2.3.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Model summary (fused): 168 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\i_kaz\\datasets\\StreetOwl\\test\\labels.cache... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<00:00,  5.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         86      0.694      0.721      0.759       0.45\n",
      "Speed: 1.8ms preprocess, 21.1ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1m..\\..\\runs\\yolov8s_basic_finetune_val2\u001b[0m\n",
      "True\n",
      "Ultralytics YOLOv8.2.93  Python-3.10.6 torch-2.3.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Model summary (fused): 218 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\i_kaz\\datasets\\StreetOwl\\test\\labels.cache... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         86      0.746      0.698      0.765      0.466\n",
      "Speed: 1.7ms preprocess, 36.7ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1m..\\..\\runs\\yolov8m_basic_finetune_val2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "for i in range(0,2):\n",
    "    model_name = yolo_models[i]\n",
    "    model_path = os.path.join(project,f'{model_name}_hyp_finetune_best_param',\"weights\",\"best.pt\")\n",
    "    print(os.path.exists(model_path))\n",
    "    model = YOLO(model_path)\n",
    "    results = model.val(data=\"data.yaml\", split=\"test\",project=project,name=f\"{yolo_models[i]}_basic_finetune_val\")\n",
    "    results_list.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuned yolov8s\n",
      "{'metrics/precision(B)': 0.6936893217212663, 'metrics/recall(B)': 0.7209302325581395, 'metrics/mAP50(B)': 0.7592400043999991, 'metrics/mAP50-95(B)': 0.4504859824335579, 'fitness': 0.48136138463020206}\n",
      "finetuned yolov8m\n",
      "{'metrics/precision(B)': 0.7461721917928935, 'metrics/recall(B)': 0.6976744186046512, 'metrics/mAP50(B)': 0.7649575861031386, 'metrics/mAP50-95(B)': 0.46594477053127187, 'fitness': 0.49584605208845856}\n"
     ]
    }
   ],
   "source": [
    "all_results = {}\n",
    "\n",
    "for i in range(0,2):\n",
    "    print(\"finetuned \"+yolo_models[i])\n",
    "    print(results_list[i].results_dict)\n",
    "    all_results[\"finetuned \"+yolo_models[i]] = results_list[i].results_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ec091_row0_col0, #T_ec091_row1_col1, #T_ec091_row2_col0, #T_ec091_row3_col0, #T_ec091_row4_col0 {\n",
       "  background-color: #000004;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ec091_row0_col1, #T_ec091_row1_col0, #T_ec091_row2_col1, #T_ec091_row3_col1, #T_ec091_row4_col1 {\n",
       "  background-color: #fcfdbf;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ec091\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ec091_level0_col0\" class=\"col_heading level0 col0\" >finetuned yolov8s</th>\n",
       "      <th id=\"T_ec091_level0_col1\" class=\"col_heading level0 col1\" >finetuned yolov8m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ec091_level0_row0\" class=\"row_heading level0 row0\" >metrics/precision(B)</th>\n",
       "      <td id=\"T_ec091_row0_col0\" class=\"data row0 col0\" >0.693689</td>\n",
       "      <td id=\"T_ec091_row0_col1\" class=\"data row0 col1\" >0.746172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec091_level0_row1\" class=\"row_heading level0 row1\" >metrics/recall(B)</th>\n",
       "      <td id=\"T_ec091_row1_col0\" class=\"data row1 col0\" >0.720930</td>\n",
       "      <td id=\"T_ec091_row1_col1\" class=\"data row1 col1\" >0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec091_level0_row2\" class=\"row_heading level0 row2\" >metrics/mAP50(B)</th>\n",
       "      <td id=\"T_ec091_row2_col0\" class=\"data row2 col0\" >0.759240</td>\n",
       "      <td id=\"T_ec091_row2_col1\" class=\"data row2 col1\" >0.764958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec091_level0_row3\" class=\"row_heading level0 row3\" >metrics/mAP50-95(B)</th>\n",
       "      <td id=\"T_ec091_row3_col0\" class=\"data row3 col0\" >0.450486</td>\n",
       "      <td id=\"T_ec091_row3_col1\" class=\"data row3 col1\" >0.465945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec091_level0_row4\" class=\"row_heading level0 row4\" >fitness</th>\n",
       "      <td id=\"T_ec091_row4_col0\" class=\"data row4 col0\" >0.481361</td>\n",
       "      <td id=\"T_ec091_row4_col1\" class=\"data row4 col1\" >0.495846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ba6c6a67a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(all_results)\n",
    "df.to_csv(\"finetuned_model_val.csv\")\n",
    "df = df.style.background_gradient(cmap='magma', axis=1)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
